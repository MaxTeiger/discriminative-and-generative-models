{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GDA_.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "J-UZ55_WR-xH",
        "qrI7jDb9U9aD",
        "LDV7iBOFo0NW"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbGF-kgxR370",
        "colab_type": "text"
      },
      "source": [
        "# Gaussian Discriminative Analysis (GDA)\n",
        "\n",
        "##### *October 8, 2019 Pr: Jae Yun JUN KIM*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8rhWu40LouB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import Librairies\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random as rd \n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbUM0Q4sQphd",
        "colab_type": "text"
      },
      "source": [
        "### Tasks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-UZ55_WR-xH",
        "colab_type": "text"
      },
      "source": [
        "#### 1. Download the data.csv file which contains one hundred of examples with two features and the corresponding label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHCoGeZgLq5P",
        "colab_type": "code",
        "outputId": "2de7ddd6-6ee8-4066-d284-fe539c68d9c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "source": [
        "# URL of the csv file containing the data on GitHub\n",
        "url = 'https://raw.githubusercontent.com/MaxTeiger/discriminative-and-generative-models/master/data.csv'\n",
        "\n",
        "# Parsing the file into a Pandas DataFrame\n",
        "datas = pd.read_csv(url, names=['x1', 'x2', 'y'])\n",
        "\n",
        "datas.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    x1   x2  y\n",
              "0  5.1  3.5  0\n",
              "1  4.9  3.0  0\n",
              "2  4.7  3.2  0\n",
              "3  4.6  3.1  0\n",
              "4  5.0  3.6  0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrI7jDb9U9aD",
        "colab_type": "text"
      },
      "source": [
        "#### 2. Read the data file, considering 80% of data as the training set and the rest for the test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKU6Qzq0VHnt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def splitTrainingTest(initialDF, train_size = 0.8):\n",
        "  \n",
        "    #Initialization\n",
        "    trainIndex, testIndex = list(), list()\n",
        "    \n",
        "    # We iterate over the DataFrame and put 80% of the inputs \n",
        "    # in the training set and the rest in the test set\n",
        "    for i in range(initialDF.shape[0]):\n",
        "        if np.random.uniform(0, 1) < train_size:\n",
        "            trainIndex += [i]\n",
        "        else:\n",
        "            testIndex += [i]\n",
        "    \n",
        "    # Locate all lines in the initial dataframe at indexes \n",
        "    # specified for each training and testing set\n",
        "    trainData = initialDF.loc[trainIndex]\n",
        "    testData = initialDF.loc[testIndex]\n",
        "    \n",
        "    # Reset index for both sets\n",
        "    trainData.reset_index(inplace = True)\n",
        "    trainData.drop(['index'], axis = 1, inplace = True)\n",
        "    trainData.head()\n",
        "    testData.reset_index(inplace = True)\n",
        "    testData.drop(['index'], axis = 1, inplace = True)\n",
        "    testData.head()\n",
        "    \n",
        "    return trainData, testData"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdoGtk5KVvkT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Splitting datas into training and testing set\n",
        "train_datas, test_datas = splitTrainingTest(datas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMPbR5hfYbiL",
        "colab_type": "code",
        "outputId": "7b3cf191-3a54-441d-c044-a4c563a38fdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        }
      },
      "source": [
        "print(\"Number of rows in training set:\", train_datas.shape[0])\n",
        "print(\"Number of rows in test set:\", test_datas.shape[0])\n",
        "print('Number of total rows: ', train_datas.shape[0]+test_datas.shape[0], \"\\n\")\n",
        "print(train_datas['y'].value_counts(), '\\n')\n",
        "print(test_datas['y'].value_counts())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of rows in training set: 78\n",
            "Number of rows in test set: 22\n",
            "Number of total rows:  100 \n",
            "\n",
            "1    41\n",
            "0    37\n",
            "Name: y, dtype: int64 \n",
            "\n",
            "0    13\n",
            "1     9\n",
            "Name: y, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PPIHjYgW0xD",
        "colab_type": "text"
      },
      "source": [
        "#### 3. Solve the classification problem using both methods that you learned in class (the training part):\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jfJ63RNLXGqR",
        "colab_type": "text"
      },
      "source": [
        "##### Logistic regression (an example of discriminative models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDV7iBOFo0NW",
        "colab_type": "text"
      },
      "source": [
        "###### Partie cours"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qh6ZyZ-h4z-",
        "colab_type": "text"
      },
      "source": [
        "Le but est de trouver le y *(output)* qui maximise la probabilité : \n",
        "\n",
        "> $P( Y = y | X )$\n",
        "\n",
        "Pour ce problème on utilise généralement la fonction sigmoide :\n",
        "\n",
        "![Fonction Sigmoide](http://saedsayad.com/images/ANN_Sigmoid.png)\n",
        "\n",
        "On dit donc que : \n",
        "\n",
        "> $P( Y = 1 | X ; Ɵ) =$ $h_Ɵ$( $X^{(i)}$ ) \n",
        "\n",
        "et que : \n",
        "\n",
        "> $P(Y=0|X;Ɵ)=1-h_Ɵ(x^{(i)})$\n",
        "\n",
        "On peut en déduire facilement que : \n",
        "\n",
        "> $P ( Y = 1 | X ; Ɵ) = h_Ɵ( X^{(i)} )^{(y)}( 1 -h_Ɵ( X^y ))^{(1 - y)}$ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSqB4O4Oo9yO",
        "colab_type": "text"
      },
      "source": [
        "---\n",
        "\n",
        "**Performance Measures : Conditional Likelihood**\n",
        "\n",
        "We use conditional probability,  so we use conditional likelihood $L(Ɵ)$\n",
        "\n",
        "The conditional likelihood is defined as : \n",
        "\n",
        "> $ L(Ɵ)=P( Y | X ; Ɵ )$\n",
        "\n",
        "But as we consider the distribution to be identically and independently distributed, we can deduce : \n",
        "> $ L(Ɵ)=$$\\prod_{i=1}^{I} P(Y^{(i)} | X^{(i)};Ɵ)$\n",
        "\n",
        "> $ L(Ɵ)=$$\\prod_{i=1}^{I} [ h_Ɵ$( $X^{(i)}$ $)^{(y^{(i)})}$ \n",
        "> $( 1 - h_Ɵ( X^{(i)})^{(1 - y^{(i)})}] $\n",
        "\n",
        "From the previous calculation.\n",
        "\n",
        "But this is not good, we are indeed multiplying probabilities many times, the likelihood will tend towards $0$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95wnsm_bBf8j",
        "colab_type": "text"
      },
      "source": [
        "The solution is to use the conditional log-likelihood : \n",
        "\n",
        "$l(\\theta) = \\log(L(\\theta)) = \\sum_{i=0}^I y^{(i)}h_{\\theta}(x^{(i)})+(1-y^{(i)})(1-h_{\\theta}(x^{(i)})$\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**The goal is finding $\\theta$ for which $l(\\theta)$ is higher**\n",
        "\n",
        "To serve this purpose, we use the gradient ascent : \n",
        "\n",
        "\n",
        "$n = {1, ... , N}$ $\\leftarrow$ Nb of features\n",
        "\n",
        "\n",
        "$\\theta_n^{(itera)} \\leftarrow \\theta_n^{(itera-1)} \\color{red}{+} \\alpha . \\frac{dl}{d\\theta_n} $ (Scalar)\n",
        "\n",
        "$\\theta^{(itera)} \\leftarrow \\theta^{(itera-1)} \\color{red}{+} \\alpha .  ▽_{\\theta}l(\\theta)$ (Vector)\n",
        "\n",
        "\n",
        "\n",
        "We need to compute :\n",
        "\n",
        "$\\frac{dl}{d\\theta_n} = \\sum_{i=0}^I (y^{(i)} - h_{\\theta}(x^{(i)}))x_n^{(i)}$\n",
        "\n",
        "Indeed, we have : \n",
        "\n",
        "> $\\theta_n^{(itera)} \\leftarrow \\theta_n^{(itera-1)} \\color{red}{+} \\alpha . \\sum_{i=0}^I (y^{(i)} - h_{\\theta}(x^{(i)})x_n^{(i)} $ \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eVSrwV0WWJVr",
        "colab_type": "text"
      },
      "source": [
        "###### Partie code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO3xi2ALXFla",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DiscriminativeClassifier():\n",
        "    \n",
        "    def __init__(self):\n",
        "        # Our two weights initialized randomly between -1 and 1\n",
        "        self.theta = None\n",
        "        \n",
        "        self.dl_theta = None\n",
        "        \n",
        "        # Learning rates\n",
        "        self.alpha = 0.005\n",
        "        \n",
        "        # Number of features\n",
        "        self.N = 0\n",
        "        \n",
        "        # Number of training examples\n",
        "        self.I = 0\n",
        "        \n",
        "        # Error\n",
        "        self.err = []\n",
        "        self.histdl = []\n",
        "        self.histTheta = []\n",
        "\n",
        "        self.y_hat = []\n",
        "        \n",
        "    \n",
        "    def sigmoid_function(self, X):\n",
        "        \"\"\"Takes an X[i] as an input and compute the sigmoid function with it, \n",
        "        gives the probability that Y=1 depending on X[i], computed with theta \n",
        "        parameters\n",
        "        \"\"\"\n",
        "        \n",
        "        h_theta = 1 / ( 1+np.exp ( np.dot ( -self.theta, X ) ) )\n",
        "        \n",
        "        return h_theta\n",
        "      \n",
        "    def c_log_likelihood(self, X, y):\n",
        "      \"\"\"\n",
        "      Compute the log likelihood given X and y \n",
        "      \"\"\"\n",
        "      l_theta = 0\n",
        "      for i in range(self.I):\n",
        "        l_theta += y[i]*self.sigmoid_function(X[i]) + (1 - y[i])*(1 - self.sigmoid_function(X[i]))\n",
        "        \n",
        "      return l_theta\n",
        "      \n",
        "    \n",
        "    def conditional_propability(self, X):\n",
        "        return None\n",
        "\n",
        "    def plot_hist(self):\n",
        "        plt.plot(np.arange(len(self.err)), self.err)\n",
        "        plt.title('Likelihood')\n",
        "        plt.show()\n",
        "        \n",
        "        plt.plot(np.arange(len(self.histTheta)), self.histTheta, label='Theta')\n",
        "        plt.legend()\n",
        "        plt.title('Theta')\n",
        "        plt.show()\n",
        "        \n",
        "        plt.plot(np.arange(len(self.histdl)), self.histdl, label='dL/dTheta')\n",
        "        plt.legend()\n",
        "        plt.title('dL')\n",
        "        plt.show()\n",
        "    \n",
        "    def c_dl_theta(self, X, y):\n",
        "        \"\"\"\n",
        "        Compute the derivative of theta given X and y \n",
        "        \"\"\"\n",
        "        self.dl_theta = np.array([0.]*self.N) \n",
        "        \n",
        "        for n in range(self.N):\n",
        "          for i in range(self.I):\n",
        "            self.dl_theta[n] += (y[i]-self.sigmoid_function(X[i]))*X[i,n]\n",
        "            \n",
        "#         print('DL/DTHETA : ', self.dl_theta)\n",
        "    \n",
        "    def fit(self, X, y, nb_epoch=50):\n",
        "        \n",
        "        # define training examples and number of features\n",
        "        self.N = X.shape[1] # Here 2 features \n",
        "        self.I = X.shape[0] # Here approx. 80 training examples\n",
        "        \n",
        "        # define an N-array for Theta and dl theta \n",
        "        self.dl_theta = np.array([0.]*self.N) \n",
        "        self.theta = np.array([np.random.normal(1.0, 0.5)] * self.N)\n",
        "        \n",
        "        print(\"Initial Theta : \", self.theta, \"\\nInitial dl/dTheta : \", self.dl_theta)\n",
        "        print(\"Number of features : \", self.N, \"\\nNumber of Tr. Examples : \", self.I)\n",
        "        \n",
        "        \n",
        "        for e in range(nb_epoch):\n",
        "          \n",
        "#           print('loop ', e )\n",
        "#           print(\"Theta : \", self.theta, \"\\tdl : \", self.dl_theta)\n",
        "          \n",
        "          #  Keep trace of the parameters\n",
        "          self.err.append(self.c_log_likelihood(X,y))\n",
        "          self.histdl.append(self.dl_theta)\n",
        "          self.histTheta.append([self.theta[0], self.theta[1]])\n",
        "          \n",
        "          # calculate dl/dtheta\n",
        "          self.c_dl_theta(X, y)                 \n",
        "          \n",
        "          # actualize theta\n",
        "          self.theta+=self.alpha*self.dl_theta\n",
        "          \n",
        "          \n",
        "          \n",
        "        self.plot_hist()\n",
        "        \n",
        "                                                                    \n",
        "        \n",
        "    def predict_one(self, X):\n",
        "      if self.sigmoid_function(X) > 0.5:\n",
        "        return 1\n",
        "      else: \n",
        "        return 0\n",
        "    \n",
        "    def predict(self, X, y):\n",
        "      \n",
        "      self.y_hat = []\n",
        "\n",
        "      # For each test example\n",
        "      print(\"|\\tx1\\t|\\tx2\\t|\\ty\\t|\\ty_hat\\t|\\n\" +\\\n",
        "      \"-\"*65)\n",
        "      for i in range(len(X)):\n",
        "        print(\"|\\t\"+str(X[i,0])+\"\\t|\\t\"+str(X[i,1])+\"\\t|\\t\"+str(y[i])+\"\\t\" \\\n",
        "             \"|\\t\"+str(self.predict_one(X[i]))+\"\\t|\")\n",
        "        print(\"-\"*65)\n",
        "\n",
        "        self.y_hat.append(self.predict_one(X[i]))\n",
        "\n",
        "    def confusion_matrix(self, y):\n",
        "\n",
        "        true_pos, false_pos, true_neg, false_neg = 0, 0, 0, 0\n",
        "\n",
        "        for i  in range(len(y)):\n",
        "          if self.y_hat[i] == 1 and y[i]==1:\n",
        "            true_pos+=1\n",
        "          elif self.y_hat[i] == 1 and y[i]==0:\n",
        "            false_pos +=1\n",
        "          elif self.y_hat[i] == 0 and y[i] ==0:\n",
        "            true_neg+=1\n",
        "          elif self.y_hat[i] == 0 and y[i] == 1:\n",
        "            false_neg+=1\n",
        "        \n",
        "        print(\"TP: {}, FP: {}, TN: {}, FN: {}\".format(true_pos, false_pos, true_neg, false_neg))\n",
        "        \n",
        "     \n",
        "        \n",
        "     \n",
        "     \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2uSZ-0LXYFB",
        "colab_type": "code",
        "outputId": "9cef2414-9cfd-4a97-bf18-c24b05f2cf8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 880
        }
      },
      "source": [
        "test = DiscriminativeClassifier()\n",
        "x_train, y_train  = train_datas.drop(columns='y').values, train_datas['y'].values\n",
        "test.fit(x_train, y_train, nb_epoch=1000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initial Theta :  [0.87672442 0.87672442] \n",
            "Initial dl/dTheta :  [0. 0.]\n",
            "Number of features :  2 \n",
            "Number of Tr. Examples :  78\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuohISPx/02szfSNoHhAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEICAYAAABLdt/UAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEICAYAAABS0fM3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAG9BJREFUeJzt3Xl0XPV99/H3V7KWmtUrGGSQXQzG\nLBZGJs4DJG4gYGMCJKQBAsXw0JgSaEJPm9RkOZA2JO4poamBkPohJiThYanLYgiGgoMTQthsqgN4\n4UEYiEUAGztxTPAiab7PH3Mlj8ajGWnmztzRvZ/XOTq693e3751rz0d3md+YuyMiIslVE3UBIiIS\nLQWBiEjCKQhERBJOQSAiknAKAhGRhFMQiIgknIJApEhm9mMz+3bUdYiUSkEgUiIzm2lmHVHXIVIs\nBYGISMIpCEQGyMyOM7MXzWybmd0DNEZdk0gYFAQiA2Bm9cADwE+BkcB/AudGWpRISBQEIgMzA6gD\nvu/une6+BHgh4ppEQqEgEBmYg4C3vW8vjW9FVYxImBQEIgPzDnCwmVlG2yFRFSMSJgWByMA8A3QB\nXzKzOjP7DHBC5gxm1pj1YznXJFJlFAQiA+Duu4DPAJcAW4DzgPsyZjkY2J718+eVrVKkOKYvphER\nSTadEYiIJJyCQEQk4RQEIiIJpyAQEUm4YVEXMBCjR4/25ubmqMsQERlSVq1a9b67jyk035AIgubm\nZlauXBl1GSIiQ4qZDejT77o0JCKScAoCEZGEUxCIiCTckLhHICLx0dnZSUdHBzt27Ii6lNhobGyk\nqamJurq6opZXEIhIRXV0dLDPPvvQ3NyM+uUrnbuzefNmOjo6mDBhQlHr0KUhEamoHTt2MGrUKIVA\nSMyMUaNGlXSGpSAQkYpTCISr1NczEUGwYcuHrHh1Y9RliIhUpUQEwak3/pJLbtfXy4pIbtdddx03\n3HADl1xyCUuWLMk5z+zZs+no6OjTtmLFCs4880xuv/12WlpaaGlpob6+nmOOOYaWlhbmz5/fu+7B\n+M53vlP0vhQjEUGwsysVdQkiMoRt376dzZs309TUlHP6pZdeSltbG21tbRx00EE8+eSTtLW1sWDB\ngqK2pyAQEamA66+/nsMPP5yTTjqJV199Ne+8K1asYObMmQA8+uijTJ48mWnTpnHfffflXa7HmjVr\nmDlzJhMnTmThwoW97T/72c844YQTaGlp4fLLL6e7u5v58+ezfft2WlpauPDCCwE455xzOP744znq\nqKNYtGhRcTuchx4fFZHIfOuh1az53R9DXeeUg/bl2k8dlXeeVatWcffdd9PW1kZXVxfTpk3j+OOP\n73f+ZcuWcc4557Bjxw6+8IUv8Itf/ILDDjuM8847b0A1rVu3jieffJJt27ZxxBFHcMUVV9De3s49\n99zD008/TV1dHV/84he58847WbBgATfffDNtbW29yy9evJiRI0eyfft2pk+fzrnnnsuoUaMG9oIM\ngM4IRCRxnnrqKT796U8zfPhw9t13X84666y88z/99NOcdNJJrFu3jgkTJjBp0iTMjIsuumhA25sz\nZw4NDQ2MHj2asWPH8t5777F8+XJWrVrF9OnTaWlpYfny5axfvz7n8gsXLmTq1KnMmDGDDRs28Npr\nrw16n/PRGYGIRKbQX+7VYP369YwfP576+vqi19HQ0NA7XFtbS1dXF+7O3Llz+e53v5t32RUrVvDE\nE0/wzDPPMHz4cGbOnBn6p7J1RiAiifOxj32MBx54gO3bt7Nt2zYeeuihfuddtmwZs2bNAmDy5Mm8\n+eabvP766wDcddddRddwyimnsGTJEjZuTD/avmXLFt56K91rdF1dHZ2dnQBs3bqVESNGMHz4cNat\nW8ezzz5b9Db7ozMCEUmcadOmcd555zF16lTGjh3L9OnTe6ddfvnlXH311QCMHz+e0aNHc9NNNwHp\nPn0WLVrEnDlzGD58OCeffDLbtm0rqoYpU6bw7W9/m9NOO41UKkVdXR233HILhx56KPPmzePYY49l\n2rRpLF68mB/+8IcceeSRHHHEEcyYMaP0FyCLuXvoKw1ba2url/LFNM3zfw7AmwvmhFWSiBRp7dq1\nHHnkkVGXMSA7d+7kxBNPHBJfjJXrdTWzVe7eWmhZXRoSEelHQ0PDkAiBUikIREQSruQgMLPxZvak\nma0xs9Vm9uWgfaSZPW5mrwW/RwTtZmYLzazdzF4ys2ml1jBQ7Rs/qNSmRESGjDDOCLqAv3f3KcAM\n4EozmwLMB5a7+yRgeTAOMBuYFPzMA24NoYYBOfXGX1ZqUyIiQ0bJQeDu77j7i8HwNmAtcDBwNnBH\nMNsdwDnB8NnATzztWWB/MxtXah0iIlKcUO8RmFkzcBzwHHCAu78TTHoXOCAYPhjYkLFYR9CWva55\nZrbSzFZu2rQptBqb5/+czm51Qici0iO0IDCzvYH/Aq529z6dh3j6GdVBPafq7ovcvdXdW8eMGRNW\nmQBM+vqy0Ps3EZGhS91Qh8DM6kiHwJ3u3tMd33s9l3yC3z3fDPM2MD5j8aagraLOWPgUP376jUpv\nVkSGIHVDXYClvyPtR8Bad78xY9JSYG4wPBd4MKP94uDpoRnA1oxLSBV13UNr+E37+1FsWkQipm6o\ndwuji4kTgb8CXjaznn5TvwYsAO41s8uAt4DPBdMeAc4A2oEPgUtDqKFon7/tOV6+7jT2aayLsgyR\nZFo2H959Odx1HngMzM7/l7i6oe6r5CBw918D/X1z8ik55nfgylK3G6aP/+sKXvzmJ6MuQ0QqJLMb\namBA3VDfcMMNrFmzprcbaoCLLrpoQH+h93RD3dDQkLMbakhffho7dmzO5RcuXMj9998P0NsNdVUF\nQRxs+dMunlu/mY9MDO+FFZEBKPCXezVQN9QJct6i8Lt2FZHqpG6o+9IZQYYdnd001tVGXYaIlJm6\noe4rUd1QFzLn2HHc8vmKdX0kkkjqhro81A11SH7+UiRPsYpIlVI31An1uz9sj7oEEZGKUhBk2baj\nK+oSRGJvKFySHkpKfT0VBFlO//6voi5BJNYaGxvZvHmzwiAk7s7mzZtpbGwseh16akhEKqqpqYmO\njg7C7FU46RobG/vtB2kgFAQ5uDvpLpREJGx1dXVMmDAh6jIkgy4N5fCTZ96KugQRkYpREOSw7t3i\nPiAiIjIUKQhERBJOQZDDXc//NuoSREQqRkEgIpJwCgIRkYRTEIiIJJyCoB+/3fxh1CWIiFSEgqAf\nc256KuoSREQqQkHQD3U+JyJJoSAQEUk4BYGISMIpCEREEk5BkEfH7/XkkIjEn4Igj99uURCISPwp\nCEREEk5BICKScAoCEZGEUxCIiCScgiCPzR/siroEEZGyUxDk8bd3/U/UJYiIlJ2CQEQk4RQEIiIJ\npyAQEUk4BYGISMIpCEREEk5BICKScAoCEZGES0QQ/Lm9zZyaZ4tadsuf9KEyEYm3UILAzBab2UYz\neyWjbaSZPW5mrwW/RwTtZmYLzazdzF4ys2lh1JDP8oavcEv9wqKW/eaDrxSeSURkCAvrjODHwKys\ntvnAcnefBCwPxgFmA5OCn3nArSHVUBY7O1NRlyAiUlahBIG7/wrYktV8NnBHMHwHcE5G+0887Vlg\nfzMbF0YdIiIyeOW8R3CAu78TDL8LHBAMHwxsyJivI2jrw8zmmdlKM1u5adOmoovo6i71L3ovcXkR\nkepWkZvF7u4M8h3V3Re5e6u7t44ZM6bobT++5r2ilxURSYJyBsF7PZd8gt8bg/a3gfEZ8zUFbWXR\nmdJf9CIi+ZQzCJYCc4PhucCDGe0XB08PzQC2ZlxCCl36ZCTte3U/oI6uQa7Bwi1IRKTKDAtjJWZ2\nFzATGG1mHcC1wALgXjO7DHgL+Fww+yPAGUA78CFwaRg1DMS5tb/m3Npf946n3Li086v8MjW1UiWI\niFSdUILA3S/oZ9IpOeZ14MowtluqGnPuqP8XAI7ecRsfMDzHXLq0JCLxlohPFg/EK41/zWi27tH+\nvr6uUkRiLvZB4IP4g35l4xVknwG0bfhDuAWJiFSZ2AfBYF1R+1DUJYiIVFTsg8AHeY3/H+vuZtig\nnywSERm6Yh8Exbhq2ANRlyAiUjEKghyuHnZf1CWIiFRM7INgMDeLRUSSKPZBUKxLa5dFXYKISEXE\nPgiKPSO4tu6n4RYiIlKl4h8EURcgIlLlYh8EpTjK3oi6BBGRslMQ5LGvfRh1CSIiZRf7IPASHhva\nix0A/PCXr4dVjohI1Yl9EJTitvrvAbBg2bqIKxERKZ/YB4FuFouI5Bf7IFASiIjkF/8gEBGRvGIf\nBIPtfTTbp2p+E1IlIiLVKfZBUKqzap+JugQRkbJSEIiIJFzsg0C9j4qI5Bf/IKiCNYiIVLPYB0Gp\nPln7IgC7ulIRVyIiUh6xD4KwLg09uvrdcFYkIlJlYh8EYSmlzyIRkWqmIBgg5YCIxFXsg6B+5/tR\nlyAiUtViHwQHbH6+5HXsxwclf0JZRKRaxT4ILIRrOkvrvxFCJSIi1Sn2QRDGX/KH1mykq1tnBCIS\nT7EPAgtpPV9Z8lJIaxIRqS6xDwIREckv/kHg+kSwiEg+8Q+CkJ72abZ3QlmPiEi1iX0QhPVBsGNt\nvfobEpFYin0QWEiXhgznnx9eE8q6RESqSfyDIKRLQwa0bfhDKOsSEakmsQ+CsDqL+379D3j57a2h\nrEtEpJrEPgjC9scdnVGXICISqsiCwMxmmdmrZtZuZvPLtp0Q+wgazg6Ove6/2dHZHdo6RUSiNiyK\njZpZLXAL8EmgA3jBzJa6e6h3Yz2VIrXzg9DWt6Du//Clzr9l8jcfZeRe9ezdMIz6YTXUmlFTY9QY\n1NYYNWbBb3qHa2sMM6M2Y57e+XqWDdaT/k3GenrmJZg3mMcAM4JfGBb8DsYt/bnqnNOC8fR06/0E\n9u55ds+fdxukRyxjPeltF9rG7mnQ9xPgme2ZU/q2Zy9j/bT3t96g9hwLDWS9e6y7nzr72ZUBL2NZ\nRVf8NRvAZ/OztzFYhZYvVEPB5Utc/8DWUdry+dbQWFdD04jhhVZQkkiCADgBaHf39QBmdjdwNhBq\nEGzZ9DtOfv17oa3vrNpn+GrnPHbQwMzDx5ByZ1d3iu6U051K34/odqc75biTbndnV1eKlDvdDqlU\nenrKHU91Y6lOhnkX5p2Q6sZS3ekPwXl62HuGPZWe7t0Y3XgqRY2nqCFFLU6NpaglPZ5u6xn3Pu0G\nvb/NHKPnhz7TIX02VcPueWpw2GNeD866MueFGksF/7T3XIcB1lND1vTMenrO5nb/JmM8V1vf8d42\n6ztPzz70XS7P8r3/AvacN3dt9O5Df8v1t43segrXGAzbnssNbJwC0/c8oy60TPZndwrPn78uL2J6\nZh09U8qxr4WuOAx2X3NN39B4GE1fW5Z3O6WKKggOBjZkjHcAH8mcwczmAfMADjnkkOK2UuqfKjms\na7wUDjwG9joBOj+Ezu3Q3QnduyDVmR72Xenxnvbe4c6+bT6IS0wG1Ia+O2XnBKcHGFjN7vFcbdSA\nZS3T89/EbPf6etjut8TecQfPbM+ax/ssmzUte31Y76CTY1vBeO+03tIya81Tf9Ded93W/75m71vP\n9rO223f7mbVm78uesqOPnOOZdfQn6/XOsd99p+feTt/acq8j3/L59hVy7cdA1pH1eu6xyEBe7/z7\nkvm6HLRfc47lwxVVEBTk7ouARQCtra1FXegfyClfUd59GbZ2QP0+UNcItfVQWxf8roeGfXa31dTt\nOb02sy0YrqmDmtr0j2X8tppguCZrWk0wXNN3/t5p2fP3tPd9E95j2GrofTPqM2w52nMs32ddex6B\nMh0RESlBVEHwNjA+Y7wpaAuV1ZThT+jjLoJP3ZR+AxYRiYGo3s1eACaZ2QQzqwfOB5aGvZHsG22h\nOPsWhYCIxEok72ju3gVcBTwGrAXudffVYW8n7CB448x7Ql2fiEg1iOwegbs/AjxS1o1YuJeGuvdp\nCnV9IiLVIN7XOEK+MnRg8+RwVygiUgViHQRWE14S7PQ69m6o2oesRESKFu8gsPB2L6UHH0UkpmId\nBGFeG7o59dnQ1iUiUk1iHQQW4mOet/lZoa1LRKSaxDsIQjwjKMdHEkREqkG8gyDEM4IvnTIptHWJ\niFSTeAdBiDeLvzjzsNDWJSJSTWIeBLqeIyJSSKyDgJDOCFamDg9lPSIi1SjWQRDWB8qeT+kTxSIS\nX/EOAn0ITESkoFgHQViK+lYcEZEhItZBoHvFIiKFxTsIoi5ARGQIiHcQhHRK8FJqYijrERGpRvEO\ngpDWM/FjF4S0JhGR6hPvINC1IRGRgmIeBOEkgfJEROIs1kEgIiKFKQhERBJOQSAiknAKggJWpw6N\nugQRkbJSEBRw8a75UZcgIlJWCoICXM8MiUjMKQgKMJzxI4dHXYaISNkoCAbg/Onjoy5BRKRsFAQF\nOKavvBSRWFMQFPABfxZ1CSIiZaUgyOOt1Fh2URd1GSIiZaUgEBFJOAWBiEjCKQhERBJOQZDHP3T+\nTdQliIiUnYIgjxd8ctQliIiUnYJARCThFAQFfOuso6IuQUSkrBQE/ViVmgTAnGPHRVyJiEh5lRQE\nZvaXZrbazFJm1po17RozazezV83s9Iz2WUFbu5lVbR/PS7v/V9QliIhURKlnBK8AnwF+ldloZlOA\n84GjgFnAD8ys1sxqgVuA2cAU4IJg3qqTCrqfVi9DIhJ3w0pZ2N3XArk6ZTsbuNvddwJvmFk7cEIw\nrd3d1wfL3R3Mu6aUOsrh3u6ZUZcgIlIR5bpHcDCwIWO8I2jrr30PZjbPzFaa2cpNmzaVqcz+7aS+\n4tsUEYlCwTMCM3sCODDHpK+7+4Phl5Tm7ouARQCtra1eru3k8utuPSkkIslRMAjc/dQi1vs2kPlt\nLk1BG3naq8bFnddEXYKISMWU69LQUuB8M2swswnAJOB54AVgkplNMLN60jeUl5aphqKlMl4WfSmN\niMRdSTeLzezTwE3AGODnZtbm7qe7+2ozu5f0TeAu4Ep37w6WuQp4DKgFFrv76pL2IGTPp47oMz5y\nL90rEJF4K/WpofuB+/uZdj1wfY72R4BHStluOV2968re4UP0pfUikgD6ZHGW3zE66hJERCpKQZDh\n4ztvjLoEEZGKUxAEvtf5Wd7yXE/JiojEm4IA2Oj7c1P3Z6IuQ0QkEokPgoe6Z/CRnTfnnFZbo0dH\nRST+SnpqaCjr9Fpm7VrA656zhwsAfjS3td9pIiJxkZgg+FrnZezPNn6TOpqXfQLd1BZcZuKYvStQ\nmYhItGIfBOfv+ga7fBgv+uFRlyIiUpViHwTPpqry6w5ERKpG4m8Wi4gknYJARCThFAT9uOovDou6\nBBGRilAQ9GP03up1VESSQUEgIpJwCoJ+1NbqpRGRZNC7XT8+19oUdQkiIhWhIOhHw7DCnzwWEYkD\nBYGISMIpCHJoPXRE1CWIiFSMgiCHu+bNiLoEEZGKURDkUKcnhkQkQfSOJyKScAqCLMfr/oCIJIyC\nIMv05pFRlyAiUlEKgiz/cJq+wEZEkkVBkGWYbhSLSMLoXS/DwguOi7oEEZGKUxBkOOPoA6MuQUSk\n4hQEgW/MOVKXhUQkkfTOF/jrkydGXYKISCQUBMCvvvIXUZcgIhKZxAfBTy87gUNGDY+6DBGRyAyL\nuoAoPXPNJxi3359FXYaISKQSFwRTm/bjn84+mqnj94+6FBGRqpCYIHhzwZyoSxARqUqxD4JbL5xG\nY52+dlJEpD+xD4LZx4yLugQRkaqW+KeGRESSTkEgIpJwJQWBmf2rma0zs5fM7H4z2z9j2jVm1m5m\nr5rZ6Rnts4K2djObX8r2RUSkdKWeETwOHO3uxwL/D7gGwMymAOcDRwGzgB+YWa2Z1QK3ALOBKcAF\nwbwiIhKRkoLA3f/b3buC0WeBpmD4bOBud9/p7m8A7cAJwU+7u693913A3cG8IiISkTDvEfxvYFkw\nfDCwIWNaR9DWX/sezGyema00s5WbNm0KsUwREclU8PFRM3sCyNVR/9fd/cFgnq8DXcCdYRXm7ouA\nRQCtra0e1npFRKSvgkHg7qfmm25mlwBnAqe4e88b9tvA+IzZmoI28rSLiEgEbPd7dxELm80CbgQ+\n7u6bMtqPAv4v6XsCBwHLgUmAkb6pfArpAHgB+Ly7ry6wnU3AW0UXCqOB90tYfijSPsdf0vYXtM+D\ndai7jyk0U6mfLL4ZaAAeNzOAZ939b9x9tZndC6whfcnoSnfvBjCzq4DHgFpgcaEQABjIjuRjZivd\nvbWUdQw12uf4S9r+gva5XEoKAnc/LM+064Hrc7Q/AjxSynZFRCQ8+mSxiEjCJSUIFkVdQAS0z/GX\ntP0F7XNZlHSzWEREhr6knBGIiEg/FAQiIgkX6yCIa0+nZjbezJ40szVmttrMvhy0jzSzx83steD3\niKDdzGxh8Dq8ZGbTot2D4gWdF/6PmT0cjE8ws+eCfbvHzOqD9oZgvD2Y3hxl3cUys/3NbEnQy+9a\nM/to3I+zmf1d8O/6FTO7y8wa43aczWyxmW00s1cy2gZ9XM1sbjD/a2Y2t9h6YhsEMe/ptAv4e3ef\nAswArgz2bT6w3N0nkf4QX0/4zSb9gb5JwDzg1sqXHJovA2szxv8F+LfgUebfA5cF7ZcBvw/a/y2Y\nbyj6d+BRd58MTCW977E9zmZ2MPAloNXdjyb9eaPzid9x/jHpnpkzDeq4mtlI4FrgI6Q/vHttT3gM\nmrvH8gf4KPBYxvg1wDVR11WmfX0Q+CTwKjAuaBsHvBoM/wdwQcb8vfMNpR/SXZIsBz4BPEz6k+rv\nA8OyjznpDy1+NBgeFsxnUe/DIPd3P+CN7LrjfJzZ3THlyOC4PQycHsfjDDQDrxR7XIELgP/IaO8z\n32B+YntGwCB6Oh3KglPh44DngAPc/Z1g0rvAAcFwXF6L7wNfBVLB+CjgD767K/TM/erd52D61mD+\noWQCsAm4PbgcdpuZ7UWMj7O7vw3cAPwWeIf0cVtFvI9zj8Ee19COd5yDIPbMbG/gv4Cr3f2PmdM8\n/SdCbJ4NNrMzgY3uvirqWipoGDANuNXdjwP+xO7LBUAsj/MI0t9RMoF0P2V7secllNir9HGNcxDk\n6wF1yDOzOtIhcKe73xc0v2dm44Lp44CNQXscXosTgbPM7E3SX2j0CdLXz/c3s56uUjL3q3efg+n7\nAZsrWXAIOoAOd38uGF9COhjifJxPBd5w903u3gncR/rYx/k49xjscQ3teMc5CF4AJgVPG9STvuG0\nNOKaQmHpHv5+BKx19xszJi0Fep4cmEv63kFP+8XB0wczgK0Zp6BDgrtf4+5N7t5M+lj+wt0vBJ4E\nPhvMlr3PPa/FZ4P5h9Rfzu7+LrDBzI4Imk4h3ZFjbI8z6UtCM8xsePDvvGefY3ucMwz2uD4GnGZm\nI4IzqdOCtsGL+oZJmW/GnEG62+vXSX+RTuQ1hbRfJ5E+bXwJaAt+ziB9bXQ58BrwBDAymN9IP0H1\nOvAy6ScyIt+PEvZ/JvBwMDwReJ7016H+J9AQtDcG4+3B9IlR113kvrYAK4Nj/QAwIu7HGfgWsA54\nBfgp6R6OY3WcgbtI3wPpJH3md1kxx5X0N0O2Bz+XFluPupgQEUm4OF8aEhGRAVAQiIgknIJARCTh\nFAQiIgmnIBARSTgFgYhIwikIREQS7v8Dwh8HIjfNGKEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrLYplqbXYMK",
        "colab_type": "code",
        "outputId": "8cbb26e8-30d0-4993-87bb-9eb75d4b1ace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 835
        }
      },
      "source": [
        "x_test, y_test  = test_datas.drop(columns='y').values, test_datas['y'].values\n",
        "test.predict(x_test, y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|\tx1\t|\tx2\t|\ty\t|\ty_hat\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t4.7\t|\t3.2\t|\t0\t|\t0\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t5.0\t|\t3.4\t|\t0\t|\t0\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t5.1\t|\t3.8\t|\t0\t|\t0\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t5.4\t|\t3.4\t|\t0\t|\t0\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t5.2\t|\t3.5\t|\t0\t|\t0\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t4.7\t|\t3.2\t|\t0\t|\t0\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t4.8\t|\t3.1\t|\t0\t|\t0\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t5.2\t|\t4.1\t|\t0\t|\t0\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t5.5\t|\t4.2\t|\t0\t|\t0\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t5.5\t|\t3.5\t|\t0\t|\t0\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t4.4\t|\t3.0\t|\t0\t|\t0\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t4.8\t|\t3.0\t|\t0\t|\t0\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t4.6\t|\t3.2\t|\t0\t|\t0\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t5.2\t|\t2.7\t|\t1\t|\t1\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t5.8\t|\t2.7\t|\t1\t|\t1\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t6.2\t|\t2.2\t|\t1\t|\t1\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t5.9\t|\t3.2\t|\t1\t|\t1\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t6.4\t|\t2.9\t|\t1\t|\t1\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t5.7\t|\t2.6\t|\t1\t|\t1\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t5.5\t|\t2.4\t|\t1\t|\t1\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t5.8\t|\t2.7\t|\t1\t|\t1\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t6.2\t|\t2.9\t|\t1\t|\t1\t|\n",
            "-----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HO4Rswx0EMNI",
        "colab_type": "code",
        "outputId": "d086d4ac-5788-4f27-8130-f2c87fc87893",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "test.confusion_matrix(y_test)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TP: 9, FP: 0, TN: 13, FN: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5M9m6jMXSae",
        "colab_type": "text"
      },
      "source": [
        "##### Gaussian Discriminant Analysis (an example of generative models)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZX0wtHADMrg4",
        "colab_type": "text"
      },
      "source": [
        "###### Partie Cours"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hWHUlKhMwfj",
        "colab_type": "text"
      },
      "source": [
        "The objective we have is to find :\n",
        "\n",
        "> $argmax_y P(X|Y)P(Y)$\n",
        "\n",
        "We supposed that Y is following Bernouilli rule : \n",
        "\n",
        "> $P(Y;\\phi) = \\phi^y \\times(1-\\phi)^{(1-y)}$ where $P(Y = 1; \\phi)\\ne0$\n",
        "     \n",
        "       \n",
        "$X|Y=0$ suit une loi normale de paramètres $N(\\mu_0, \\epsilon)$\n",
        "\n",
        "$X|Y=1$ suit une loi normale de paramètres $N(\\mu_1, \\epsilon)$\n",
        "\n",
        "By definition, we assume that :\n",
        "\n",
        "$P(X|Y=0) = \\frac{1}{(2\\pi)^{\\frac{N}{2}}(det(\\epsilon))^{\\frac{1}{2}}}.exp[-(X-\\mu_0)^{T}\\epsilon^{-1}(X-\\mu_0)]$\n",
        "\n",
        "$P(X|Y=1) = \\frac{1}{(2\\pi)^{\\frac{N}{2}}(det(\\epsilon))^{\\frac{1}{2}}}.exp[-(X-\\mu_1)^{T}\\epsilon^{-1}(X-\\mu_1)]$\n",
        "\n",
        "----\n",
        "\n",
        "Here we use joint probabilities, so we have to compute the joint log-likelihood : \n",
        "\n",
        "> $l(\\theta)=logP(X, Y; \\theta)$\n",
        ">\n",
        "> $l(\\theta)=log\\prod_{i=1}^I P(X^{(i)}|Y^{(i)};\\theta)P(Y^{(i)})  $ \n",
        "\n",
        "avec $\\theta = (\\phi, \\mu_0, \\mu_1, \\epsilon)$\n",
        "\n",
        "With the Maximum Likelihood Estimation (MLE), we can compute : \n",
        "\n",
        "${\\mu_0}_{MLE} = \\frac{\\sum_{i=1}^I || \\{y^{(i)} =0\\}x^{(i)}}{\\sum_{i=1}^I || \\{y^{(i)}=0\\}}$\n",
        "\n",
        "\n",
        "${\\mu_1}_{MLE} = \\frac{\\sum_{i=1}^I || \\{y^{(i)} =1\\}x^{(i)}}{\\sum_{i=1}^I || \\{y^{(i)}=1\\}}$\n",
        "\n",
        "\n",
        "${\\phi}_{MLE} = \\frac{\\sum_{i=1}^I || \\{y^{(i)} =1\\}}{I}$\n",
        "\n",
        "$\\epsilon_{MLE} = \\frac{1}{I}\\sum_{i=1}^I (X^{(i)}-\\mu_{y^{(i)}})(X^{(i)}-\\mu_{y^{(i)}})^T$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjhIKDmKWYKc",
        "colab_type": "text"
      },
      "source": [
        "###### Partie code\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWx6ysTsXXBH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GenerativeClassifier():\n",
        "    \n",
        "    def __init__(self):\n",
        "      \n",
        "      # Model parameters\n",
        "      self.mu_0 = None\n",
        "      self.mu_1 = None\n",
        "      self.phi = None\n",
        "      self.eps = None\n",
        "      \n",
        "      # Learning rates\n",
        "      self.alpha = 0.005\n",
        "        \n",
        "      # Number of features\n",
        "      self.N = 0\n",
        "        \n",
        "      # Number of training examples\n",
        "      self.I = 0\n",
        "\n",
        "      self.y_hat = []\n",
        "              \n",
        "    def c_log_likelihood(self, X, y):\n",
        "      \"\"\"\n",
        "      Compute the log likelihood given X and y \n",
        "      \"\"\"\n",
        "\n",
        "      return l_theta\n",
        "      \n",
        "    \n",
        "    def c_px_y0(self, X):\n",
        "        \"\"\" \n",
        "        \"\"\"\n",
        "        det_eps = np.linalg.det(self.eps)\n",
        "        pi = np.pi\n",
        "        X = np.matrix(X)\n",
        "        px_y0 = ( 1 / ( ((2*pi)**(self.N/2)) * det_eps**(1/2) ) ) \\\n",
        "              * np.exp( (-1/2)*( X-self.mu_0 ) * np.linalg.inv(self.eps) \\\n",
        "              * (X.T-self.mu_0) )  \n",
        "       \n",
        "        return px_y0\n",
        "\n",
        "    def c_px_y1(self, X):\n",
        "        \"\"\"\n",
        "        \"\"\"\n",
        "        \n",
        "        det_eps = np.linalg.det(self.eps)\n",
        "        pi = np.pi\n",
        "        X = np.matrix(X)\n",
        "        px_y1 = ( 1 / ( (2*pi)**(self.N/2) * det_eps**(1/2) ) ) \\\n",
        "              * np.exp( (-1/2)*( X-self.mu_1 ) * np.linalg.inv(self.eps) \\\n",
        "              * (X.T-self.mu_1) )  \n",
        "\n",
        "        return px_y1\n",
        "      \n",
        "    def c_py(self, y):\n",
        "      \"\"\"\n",
        "      \"\"\"\n",
        "      p_y = self.phi**(y) * (1-self.phi)**(1-y)\n",
        "      \n",
        "      return p_y\n",
        "    \n",
        "    def predict_one(self, X):\n",
        "\n",
        "      px_y0 = self.c_px_y0(X)\n",
        "      px_y1 = self.c_px_y1(X)\n",
        "      py0 = self.c_py(0)\n",
        "      py1 = self.c_py(1)\n",
        "      \n",
        "      if px_y0*py0 > px_y1*py1:\n",
        "        return 0\n",
        "      elif px_y1*py1 > px_y0*py0:\n",
        "        return 1 \n",
        "        \n",
        "    def c_phi(self, y):\n",
        "      num = 0\n",
        "        \n",
        "      for i in range(self.I):\n",
        "        if y[i] == 1:\n",
        "          num+=1\n",
        "              \n",
        "      return num/self.I\n",
        "    \n",
        "    def c_mu_0(self, X, y):\n",
        "      \n",
        "        num, denom = 0, 0\n",
        "        \n",
        "        for i in range(self.I):\n",
        "          if y[i] == 0:\n",
        "            denom += 1\n",
        "            for n in range(self.N):\n",
        "              num+=X[i, n]\n",
        "              \n",
        "        return num/denom\n",
        "      \n",
        "    def c_mu_1(self, X, y):\n",
        "        \n",
        "        num, denom = 0, 0\n",
        "        \n",
        "        for i in range(self.I):\n",
        "          if y[i] == 1:\n",
        "            denom += 1\n",
        "            for n in range(self.N):\n",
        "              num+=X[i, n]\n",
        "              \n",
        "        return num/denom\n",
        "      \n",
        "    def c_eps(self, X, y):\n",
        "        \"\"\"\n",
        "        Should return a NxN matrix \n",
        "        \"\"\"\n",
        "        num = np.matrix([[0.]*self.N]*self.N)\n",
        "        \n",
        "        for i in range(self.I):\n",
        "          \n",
        "          temp = np.matrix([0]*self.N)\n",
        "          if y[i]==0:\n",
        "            temp = np.matrix(X[i])-self.mu_0\n",
        "            num += np.dot(temp.T, temp)\n",
        "          elif y[i]==1:\n",
        "            temp = np.matrix(X[i])-self.mu_1\n",
        "            num += np.dot(temp.T, temp)\n",
        "\n",
        "        eps = num/self.I\n",
        "        \n",
        "        return eps\n",
        "    \n",
        "    \n",
        "    def fit(self, X, y):\n",
        "        \n",
        "        # define training examples and number of features\n",
        "        self.N = X.shape[1] # Here 2 features \n",
        "        self.I = X.shape[0] # Here approx. 80 training examples\n",
        "        \n",
        "        self.mu_0 = self.c_mu_0(X, y)\n",
        "        self.mu_1 = self.c_mu_1(X, y)\n",
        "        self.phi = self.c_phi(y)\n",
        "        self.eps = self.c_eps(X, y)\n",
        "        \n",
        "        print(\"MU 0 : \", self.mu_0)\n",
        "        print(\"MU 1 : \", self.mu_1)\n",
        "        print(\"Phi  : \", self.phi)\n",
        "        print(\"Epsilon : \", self.eps)\n",
        "        \n",
        "        \n",
        "    def predict(self, X, y):\n",
        "      \n",
        "      # For each test example\n",
        "      print(\"|\\tx1\\t|\\tx2\\t|\\ty\\t|\\ty_hat\\t|\\n\" +\\\n",
        "      \"-\"*65)\n",
        "      for i in range(len(X)):\n",
        "        print(\"|\\t\"+str(X[i,0])+\"\\t|\\t\"+str(X[i,1])+\"\\t|\\t\"+str(y[i])+\"\\t\" \\\n",
        "             \"|\\t\"+str(self.predict_one(X[i]))+\"\\t|\")\n",
        "        print(\"-\"*65)\n",
        "\n",
        "        self.y_hat.append(self.predict_one(X[i]))\n",
        "\n",
        "    def confusion_matrix(self, y):\n",
        "\n",
        "        true_pos, false_pos, true_neg, false_neg = 0, 0, 0, 0\n",
        "\n",
        "        for i  in range(len(y)):\n",
        "          if self.y_hat[i] == 1 and y[i]==1:\n",
        "            true_pos+=1\n",
        "          elif self.y_hat[i] == 1 and y[i]==0:\n",
        "            false_pos +=1\n",
        "          elif self.y_hat[i] == 0 and y[i] ==0:\n",
        "            true_neg+=1\n",
        "          elif self.y_hat[i] == 0 and y[i] == 1:\n",
        "            false_neg+=1\n",
        "        \n",
        "        print(\"TP: {}, FP: {}, TN: {}, FN: {}\".format(true_pos, false_pos, true_neg, false_neg))\n",
        "        \n",
        "     \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFgcniIws8ZR",
        "colab_type": "code",
        "outputId": "70ff4527-adbb-4ccd-f2da-1c7d11fd901a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "model = GenerativeClassifier()\n",
        "x_train, y_train  = train_datas.drop(columns='y').values, train_datas['y'].values\n",
        "model.fit(x_train, y_train)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MU 0 :  8.424324324324328\n",
            "MU 1 :  8.739024390243907\n",
            "Phi  :  0.5256410256410257\n",
            "Epsilon :  [[ 9.8158098  16.92846154]\n",
            " [16.92846154 30.66239533]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXRbyiTo92Tc",
        "colab_type": "code",
        "outputId": "d18dd739-95e3-4003-ba23-59da61f2eb73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 852
        }
      },
      "source": [
        "x_test, y_test  = test_datas.drop(columns='y').values, test_datas['y'].values\n",
        "model.predict(x_test, y_test)\n",
        "model.confusion_matrix(y_test)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "|\tx1\t|\tx2\t|\ty\t|\ty_hat\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t4.7\t|\t3.2\t|\t0\t|\t0\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t5.0\t|\t3.4\t|\t0\t|\t0\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t5.1\t|\t3.8\t|\t0\t|\t0\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t5.4\t|\t3.4\t|\t0\t|\t0\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t5.2\t|\t3.5\t|\t0\t|\t0\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t4.7\t|\t3.2\t|\t0\t|\t0\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t4.8\t|\t3.1\t|\t0\t|\t0\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t5.2\t|\t4.1\t|\t0\t|\t0\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t5.5\t|\t4.2\t|\t0\t|\t0\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t5.5\t|\t3.5\t|\t0\t|\t0\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t4.4\t|\t3.0\t|\t0\t|\t0\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t4.8\t|\t3.0\t|\t0\t|\t0\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t4.6\t|\t3.2\t|\t0\t|\t0\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t5.2\t|\t2.7\t|\t1\t|\t1\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t5.8\t|\t2.7\t|\t1\t|\t1\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t6.2\t|\t2.2\t|\t1\t|\t1\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t5.9\t|\t3.2\t|\t1\t|\t1\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t6.4\t|\t2.9\t|\t1\t|\t1\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t5.7\t|\t2.6\t|\t1\t|\t1\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t5.5\t|\t2.4\t|\t1\t|\t1\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t5.8\t|\t2.7\t|\t1\t|\t1\t|\n",
            "-----------------------------------------------------------------\n",
            "|\t6.2\t|\t2.9\t|\t1\t|\t1\t|\n",
            "-----------------------------------------------------------------\n",
            "TP: 9, FP: 0, TN: 13, FN: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cl3uFDojSk9Y",
        "colab_type": "text"
      },
      "source": [
        "#### 4. Compare the results of training with the two methods."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qFE2ju3Sm74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yascxDh-Snmh",
        "colab_type": "text"
      },
      "source": [
        "#### 5. Test the optimized parameters with the test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXVTEL8TSqVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}